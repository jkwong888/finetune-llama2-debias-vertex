{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3V6K4ND1tg2"
      },
      "source": [
        "# Quantization Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgtzWBNo1tg3"
      },
      "source": [
        "## Introduction\n",
        "In this demo, we will employ PEFT (LoRA) and Quantization techniques to fine-tune the Llama2-7b model, aiming to debias and detoxify text. We will utilize a specific dataset located at `../../data/debiased_profanity_check_with_keywords.csv`.\n",
        "\n",
        "This notebook will guide you through the process, showcasing the steps involved in fine-tuning the model to produce a debiased and detoxified output from biased or toxic text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsFiglvv1tg4"
      },
      "source": [
        "## Importing Libraries\n",
        "This cell imports libraries for dataset loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4d7FP5zT4J6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514928157,
          "user_tz": -480,
          "elapsed": 23002,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "70a6805a-c5c1-4037-8b9f-bcb196782015"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os"
      ],
      "metadata": {
        "id": "zrU6naPnT0Eh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514953030,
          "user_tz": -480,
          "elapsed": 20379,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruIA7QezZEqE"
      },
      "source": [
        "## Configuring Directory Paths for Model Weights, Dataset, and Model Storage\n",
        "This cell specifies the directory paths for storing model checkpoints, adapter models, merged models, and the dataset necessary for the task. We will load the test set to perform inference against the finetuned model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"jkwng-llama-experiments\"\n",
        "model_dir = \"quantized_llama2-7b-chat-hf_20240702164528\"\n",
        "model_bucket_prefix = \"llama2\"\n",
        "model_path = f\"gs://{bucket_name}/{model_bucket_prefix}/{model_dir}\""
      ],
      "metadata": {
        "id": "ogBddl2ykGZy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514955698,
          "user_tz": -480,
          "elapsed": 540,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FXcRYCLoysx8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514957881,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#DATASET_PATH = \"../../data/debiased_profainty_check_with_keywords.csv\" # dataset of biased and corresponding debiased text\n",
        "DATASET_PATH = f\"{model_path}/dataset/test/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhcIAAa41tg7"
      },
      "source": [
        "## Creating a HuggingFace Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IgkRJzym1tg7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514966975,
          "user_tz": -480,
          "elapsed": 6737,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def create_hf_dataset_from_csv(csv_path):\n",
        "  dataset = load_dataset('arrow', data_files=csv_path)\n",
        "  return dataset\n",
        "\n",
        "dataset = create_hf_dataset_from_csv(f\"{DATASET_PATH}data-00000-of-00001.arrow\")\n",
        "#dataset = dataset.train_test_split(test_size=0.1)\n",
        "dataset = dataset.select_columns([\"biased_text\", \"debiased_text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6dKJYUhhuX5"
      },
      "source": [
        "Here are the first 3 samples of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oBDGkIl1tg7",
        "outputId": "0efa565f-cc6e-4fec-b9ce-424850e50c4e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514970412,
          "user_tz": -480,
          "elapsed": 471,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n",
            "{'biased_text': \"`` : I do n't think anyone is saying that he is a jackass . It 's about reactions to him , not him , himself . And the next section goes on to list a group of feminist theorists who use psychoanalytic theory.— ``\", 'debiased_text': \"I don't believe anyone is claiming that he is unpleasant. It is more about the reactions towards him, rather than his own character. Additionally, the next section discusses a group of feminist theorists who utilize psychoanalytic theory.\"} \n",
            "\n",
            "{'biased_text': \"its UNAFFORDABLE , its unsustainable , ITS all that and far worst . ...................................... so ? if govt do n't crash economy canada and its society is going towards slow and steady death . O AND DO N'T WORRY ABOUT DEBT SLAVES WITH BIGGER HOUSES AND BIGGER CARS . THEY ARE THE BIGGEST PART OF PROBLEM .\", 'debiased_text': 'It is unreasonably expensive, and the current situation is not sustainable. Furthermore, if the government does not take action, Canada and its society will face gradual decline. It is important to address the issue of individuals burdened with debt while trying to attain bigger houses and cars, as they contribute significantly to the problem.'} \n",
            "\n",
            "{'biased_text': 'I was not referring to WW2 . I was referring to what has been happening in those European countries in the past 3 decades . And I reject strongly your comparison of the brave young men of the Western Alliance who fought heroic battles with the Nazis to overthrow a brutal dictator and stop the slaughter of millions of Jews to Islamic terrorists and haters of Liberal Western democracies .', 'debiased_text': 'I was not discussing World War 2. I was discussing the events that have occurred in European countries over the last 30 years. I strongly disagree with comparing the courageous young men from the Western Alliance, who fought against the Nazis to save millions of Jews and overthrow a cruel dictator, to Islamic terrorists and individuals who dislike liberal Western democracies.'} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset[\"train\"]))\n",
        "\n",
        "for i in range(3):\n",
        "    sample = dataset[\"train\"][i]\n",
        "    print(sample, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9h-IvkWhuX6"
      },
      "source": [
        "## Loading Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1suCmeTsypwj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720514979454,
          "user_tz": -480,
          "elapsed": 530,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    instruction = (\n",
        "        \" You are a text debiasing bot, you take as input a\"\n",
        "        \" text and you output its debiased version by rephrasing it to be\"\n",
        "        \" free from any age, gender, political, social or socio-economic\"\n",
        "        \" biases, without any extra outputs. Debias this text by rephrasing\"\n",
        "        \" it to be free of bias: \"\n",
        "    )\n",
        "    output_text = []\n",
        "    for i in range(len(examples[\"biased_text\"])):\n",
        "        input_text = examples[\"biased_text\"][i]\n",
        "        response = examples[\"debiased_text\"][i]\n",
        "\n",
        "        text = f'''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "        ### Instruction:\n",
        "        {instruction}\n",
        "\n",
        "        ### Input:\n",
        "        {input_text}\n",
        "\n",
        "        ### Response:\n",
        "        {response}\n",
        "        '''\n",
        "\n",
        "        output_text.append(text)\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R81JK48UhuX9"
      },
      "source": [
        "## Load and Test Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqtVHU2AhuX9"
      },
      "source": [
        "### Trained Model Generation\n",
        "Here we test the performance of the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Get the default cloud project id.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]"
      ],
      "metadata": {
        "id": "rGZTjNEUTmVi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720515014596,
          "user_tz": -480,
          "elapsed": 14048,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_name = \"1398031233740439552\"\n",
        "aip_endpoint_name = (\n",
        "     f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint_name}\"\n",
        ")\n",
        "endpoint = aiplatform.Endpoint(aip_endpoint_name)"
      ],
      "metadata": {
        "id": "DsmQmr6iTWQC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720515018539,
          "user_tz": -480,
          "elapsed": 1607,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 256\n",
        "temperature = 1.0\n",
        "top_p = 0.9\n",
        "top_k = 1"
      ],
      "metadata": {
        "id": "ejNmNi9Or-CS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720522608369,
          "user_tz": -480,
          "elapsed": 467,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "slHQGiLmhuX9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720542780427,
          "user_tz": -480,
          "elapsed": 109663,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "instruction = (\n",
        "    \" You are a text debiasing bot, you take as input a\"\n",
        "    \" text and you output its debiased version by rephrasing it to be\"\n",
        "    \" free from any age, gender, political, social or socio-economic\"\n",
        "    \" biases, without any extra outputs. Debias this text by rephrasing\"\n",
        "    \" it to be free of bias: \"\n",
        ")\n",
        "\n",
        "instances = []\n",
        "predictions = []\n",
        "references = []\n",
        "for i in range(100):\n",
        "  input_text = dataset[\"train\"][i][\"biased_text\"]\n",
        "  expected = dataset[\"train\"][i][\"debiased_text\"]\n",
        "  references.append(expected)\n",
        "  #print(input_text)\n",
        "  text = f'''\n",
        "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input_text}\n",
        "\n",
        "### Response:\n",
        "  '''\n",
        "\n",
        "  instances = [\n",
        "    {\n",
        "        \"prompt\": text,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"top_k\": top_k,\n",
        "        #\"n\": 1,\n",
        "        \"stop\": [\"        \"],\n",
        "        #\"stop_token_ids\": [-1],\n",
        "    },\n",
        "  ]\n",
        "  response = endpoint.predict(instances=instances)\n",
        "\n",
        "  for prediction in response.predictions:\n",
        "    #print(prediction)\n",
        "    output_pred = prediction.split(\"Output:\\n\", 1)[1]\n",
        "    predictions.append(output_pred)\n",
        "    #print(f\"output: {output_pred}\")\n",
        "    break\n",
        "\n",
        "  #print(f\"expected: {expected}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0gWfp3rF9si",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720541749917,
          "user_tz": -480,
          "elapsed": 9218,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8a71fa77-132c-4dfc-8129-d0dfcd27a250"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m727.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate rouge score\n",
        "\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\", trust_remote_code=True)\n",
        "results = rouge.compute(predictions=predictions,\n",
        "                        references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zpgEhFWzqLh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720543448802,
          "user_tz": -480,
          "elapsed": 1108,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9c239d7e-a2b6-4d40-c17c-2f5fe04f03c7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.5253818154145768, 'rouge2': 0.32276671219613373, 'rougeL': 0.462837425614692, 'rougeLsum': 0.46812229973405917}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "quantization-inference.ipynb"
    },
    "kernelspec": {
      "display_name": "finetune_demo",
      "language": "python",
      "name": "finetune_demo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}